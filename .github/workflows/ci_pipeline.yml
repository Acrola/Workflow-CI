name: CI/CD MLflow Pipeline - Auto Retrain & Deploy

on:
  push:
    branches:
      - main # Trigger on pushes to the main branch
  workflow_dispatch: # Can also manually trigger from GitHub UI

env:
  # --- MLflow Configuration ---
  MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
  MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
  MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}

  # --- Docker Hub Configuration ---
  DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
  DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
  DOCKER_REPO: acrola/proyek_sml_kenny

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest # Use the latest Ubuntu runner

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4 # Action to check out your repository code

      - name: Setup Conda Environment
        uses: conda-incubator/setup-miniconda@v3 # Action to set up Miniconda
        with:
          auto-update-conda: true
          python-version: '3.12' # Ensure this matches your conda.yaml
          auto-activate-base: false # Do not auto-activate base env to avoid conflicts

      - name: Get Best Model Run ID from Parent Tuning Run
        id: get_best_run # This ID remains the same
        working-directory: MLProject
        run: |
          # Initialize conda for the current shell session
          source $(conda info --base)/etc/profile.d/conda.sh

          # Activate the specific environment defined in conda.yaml
          conda activate mlflow-env

          # Install MLflow explicitly to ensure the CLI is available
          conda install -c conda-forge mlflow

          python -c "
          import mlflow
          from mlflow.tracking import MlflowClient
          import os
          
          client = MlflowClient()
          
          # --- Configuration ---
          # IMPORTANT: This is the exact name of your parent tuning run
          PARENT_RUN_NAME = 'ParameterGrid_Hyperparameter_Tuning_Parent_Run' # <--- This is updated with your specific run name!
          
          # --- Find the Parent Tuning Run by its exact name (mlflow.runName tag) ---
          runs = client.search_runs(
              experiment_ids=1,
              filter_string=f\"tags.mlflow.runName = '{PARENT_RUN_NAME}'\", # Filter by the exact run name
              order_by=['start_time DESC'], # Get the most recent one if there are multiple with the same name
              max_results=1
          )
          
          if not runs:
              print(f'Error: Parent run \"{PARENT_RUN_NAME}\" not found. Please check the run name in DagsHub/MLflow UI.')
              exit(1)
          
          parent_run = runs[0]
          print(f'Found parent tuning run: {parent_run.info.run_id} (Name: {parent_run.data.tags.get(\'mlflow.runName\', \'N/A\')})')
          
          # --- Retrieve the Best Model Run ID ---
          # This checks if the parent run logged the ID of its best child run as a parameter.
          # Common parameter names are 'best_child_run_id' or 'best_model_run_id'.
          best_child_run_id = parent_run.data.params.get('best_child_run_id') or parent_run.data.params.get('best_model_run_id')
          
          if best_child_run_id:
              retrieved_run_id = best_child_run_id
              print(f'Retrieved best model run ID from parent run parameters: {retrieved_run_id}')
          else:
              # Fallback: If no specific 'best_child_run_id' parameter is found,
              # assume the parent run itself either directly contains the best model,
              # or this is the run ID to use for artifacts (e.g., if parent directly registered the model).
              print('Warning: No specific best_child_run_id parameter found in parent run. Using parent run_id as artifact source.')
              retrieved_run_id = parent_run.info.run_id
          
          # --- Output the Run ID for subsequent steps ---
          # This line writes the retrieved_run_id to the GITHUB_OUTPUT file,
          # making it accessible as ${{ steps.get_best_run.outputs.retrieved_model_run_id }}
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f'retrieved_model_run_id={retrieved_run_id}\n')
          print(f'Set GITHUB_OUTPUT: retrieved_model_run_id={retrieved_run_id}')
          " # End of Python script

      - name: Build and Push Docker Image
        working-directory: MLProject # Ensure working directory is correct for Dockerfile context
        run: |
          # Initialize conda for this shell session and activate the environment
          source $(conda info --base)/etc/profile.d/conda.sh
          conda activate mlflow-env

          # Login to Docker Hub using the secrets
          echo "${{ secrets.DOCKER_PASSWORD }}" | docker login --username "${{ secrets.DOCKER_USERNAME }}" --password-stdin

          # Build the Docker image using the MLflow run ID obtained from the previous step
          # Note: The MLflow Run ID is accessed here using the step ID 'get_best_run'
          mlflow models build-docker \
            --model-uri "runs:/${{ steps.get_best_run.outputs.retrieved_model_run_id }}/model" \
            --name "$DOCKER_REPO" \
            --enable-mlserver # This option includes MLflow's MLServer deployment components

          # Push the built Docker image to Docker Hub
          docker push "$DOCKER_REPO":latest # Pushes the image tagged as 'latest' (you can use specific tags if you implement versioning)
